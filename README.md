# eestech-hackathon
# Hackathon Submission: Customer Experience Enhancement with Public Data and Generative AI

## Introduction
This repository contains the submission of Team 10 for the Hackathon organized by EESTEC LC Aachen in partnership with Infineon. Our project aims to enhance customer experience using public data and generative AI.

## Problem Statement
The topic of the hackathon is "How can we improve customer experience with public data and generative AI?". Our team proposes a solution using a Language Model (LLM)-based model. The model provides feedback to different personas, acting as customers, by analyzing their comments and suggesting improvements. More deatils on problem statement can be found at [github](https://github.com/Infineon/hackathon)

## Solution Overview
Our solution is based on a Language Model (LLM) that analyzes customer comments and provides tailored feedback to improve their experience. We have identified and defined customer experience metrics, both abstract and non-abstract, by considering various customer personas and viewpoints. By leveraging public data and generative AI, our model offers effective and consistent predictions on how issues and comments can be handled better to enhance customer satisfaction. 

## Key Features
- Language Model (LLM)-based solution
- Feedback generation for different customer personas and the end-user customer.
- Definition and analysis of abstract and non-abstract customer experience metrics.
- Leveraging public data and generative AI for enhanced predictions.

## How It Works
1. **Data Collection**: We gather customer comments and related data from public sources. For our current dummy implementation we used the pickle data of github issues (with user comments). 
2. **Preprocessing**: The data is preprocessed to remove noise and irrelevant information. We identified that some of the entries in the master pickle file comprised of Bot or automated github pull-requests and pull-requests in general which we processed as not relevant to the task at hand and so were discarded due to the fact that any inference derieved from such issues would not contribute to improving customer experience.
3. **Model Selection**: We selected the Language Model (LLM) with respect to the computational and compatibility requirements of the task at hand. It was noted that although real time behaviour is not required, the model should process eaxh isuue within 10 minutes of standard time in a normal PC equipped with 8GB CPU RAM. We used a na√ève chat-based state-of-the-art LLM since it can be remarked that the train data was not enough to notice any change in the model's output or performance.  
4. **Feedback Generation**: The model analyzes customer comments and generates feedback tailored to different personas. Another key feature of the model is to provide different feedback to different personas using them, after consideration of their responsibilities, goals etc.
5. **Evaluation Metric Definition**: Another key endevour in the project is to define customer experience. We considered customer experience with respect to different personas within the organisation and the customer (end-user) as well, outside the organisation. Thus many numerable and abstract metrics.
6. **Evaluation**: We evaluate the effectiveness of the feedback generated by the model using various custom-defined metrics.

## Customer Experience Definition:
The tool was to be used by 4 users of different personas, Harald, Julian, Daniel and Sarah, as an example. These users and many other part of the company used the tool in order to get feedback to ultimately better the customer experience. So, we put us into their roles and also to the shoes of the customer and identified the following parameters to be used as performance metrics by our LLM.
- Response Time: calculate the time between creation of the issue and the first comment to the issue and evaluate if that is reasonable with respect to the issue.
- Resolution Time: calculate the time between creation of the issue and the resolution to the issue and evaluate if that is reasonable with respect to the issue.
- Response Effectiveness: read the comments and the sequence of comments to the issue and evaluate if that helps the customer or in resolution of the issue.
- Empathy and Friendliness: read the tone of users' comments to the issue and evaluate if the comments are valid, helpful and unbaised especially with respect to knowledge level and experience of the user.
- Customer Satisfaction: read customer comments (if any) and evaluate if the activity in the issue was helpful to the customer. 

The parameters were identified as being the most important to the end-user, the customer and are listed in no particular order. These metrics were used in the prompt engineering and the LLM should consider them while making comments on the user comments to better customer experience.

## Prompt Engineering: 
Prompt engineering involves crafting specific prompts or instructions given to a language model to produce desired outputs. The goal of this exercise is to guide the model towards generating outputs that align with the intended objective. The focus on Prompt Engineering is to ask the correct questions and getting the precise and homogenous answers and parsing them in an effectively readable and understandble format. 

## Getting Started
To get started with our project, follow these steps:
1. Clone this repository to your local machine.
2. Install the required dependencies as mentioned in the `requirements.txt` file.
3. Run the main script to train the model and generate feedback.

## Contributors
- [Manas Mehrotra](https://github.com/mechgguy)
- [Kh Safkat Amin](https://github.com/khsafkatamin)
- [Team Member 3](https://github.com/teammember3)

## Acknowledgements
We would like to thank EESTEC LC Aachen and Infineon for organizing this hackathon and providing us with the opportunity to work on such an exciting project.

## License
This project is licensed under the [MIT License](https://www.mit.edu/~amini/LICENSE.md).
